{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 10.671979,
     "end_time": "2024-01-14T03:18:00.193134",
     "exception": false,
     "start_time": "2024-01-14T03:17:49.521155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"jax\" # you can also use tensorflow or torch\n",
    "\n",
    "#import keras_cv\n",
    "import keras\n",
    "#from keras import ops\n",
    "import tensorflow as tf\n",
    "import keras_cv\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 0.019435,
     "end_time": "2024-01-14T03:18:00.246368",
     "exception": false,
     "start_time": "2024-01-14T03:18:00.226933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.13.1\n",
      "Keras: 2.13.1\n",
      "KerasCV: 0.6.4\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Keras:\", keras.__version__)\n",
    "print(\"KerasCV:\", keras_cv.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010922,
     "end_time": "2024-01-14T03:18:00.26855",
     "exception": false,
     "start_time": "2024-01-14T03:18:00.257628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# âš™ï¸ | Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 0.018795,
     "end_time": "2024-01-14T03:18:00.298534",
     "exception": false,
     "start_time": "2024-01-14T03:18:00.279739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    verbose = 1  # Verbosity\n",
    "    seed = 42  # Random seed\n",
    "    preset = \"efficientnetv2_b2_imagenet\"  # Name of pretrained classifier\n",
    "    image_size = [400, 300]  # Input image size\n",
    "    epochs = 13 # Training epochs\n",
    "    batch_size = 64  # Batch size\n",
    "    lr_mode = \"cos\" # LR scheduler mode from one of \"cos\", \"step\", \"exp\"\n",
    "    drop_remainder = True  # Drop incomplete batches\n",
    "    num_classes = 6 # Number of classes in the dataset\n",
    "    fold = 0 # Which fold to set as validation data\n",
    "    class_names = ['Seizure', 'LPD', 'GPD', 'LRDA','GRDA', 'Other']\n",
    "    label2name = dict(enumerate(class_names))\n",
    "    name2label = {v:k for k, v in label2name.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010907,
     "end_time": "2024-01-14T03:18:00.32063",
     "exception": false,
     "start_time": "2024-01-14T03:18:00.309723",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# â™»ï¸ | Reproducibility \n",
    "Sets value for random seed to produce similar result in each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 0.018371,
     "end_time": "2024-01-14T03:18:00.350074",
     "exception": false,
     "start_time": "2024-01-14T03:18:00.331703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010888,
     "end_time": "2024-01-14T03:18:00.372053",
     "exception": false,
     "start_time": "2024-01-14T03:18:00.361165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸ“ | Dataset Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 0.017704,
     "end_time": "2024-01-14T03:18:00.400852",
     "exception": false,
     "start_time": "2024-01-14T03:18:00.383148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_PATH = \"..\"\n",
    "SPEC_DIR = \"../dataset/hms-hbac\"\n",
    "os.makedirs(SPEC_DIR+'/train_spectrograms', exist_ok=True)\n",
    "os.makedirs(SPEC_DIR+'/test_spectrograms', exist_ok=True)\n",
    "os.makedirs(SPEC_DIR+'/train_eegs', exist_ok=True)\n",
    "os.makedirs(SPEC_DIR+'/test_eegs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HMS_PATH = '/kaggle/input/hms-harmful-brain-activity-classification'\n",
    "VER = 50\n",
    "DATA_TYPE = 'KERFW' # K|E|R|KE|KR|ER|KER\n",
    "\n",
    "USE_PROCESSED = True # Use processed downsampled Raw EEG \n",
    "submission = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011434,
     "end_time": "2024-01-14T03:18:00.472401",
     "exception": false,
     "start_time": "2024-01-14T03:18:00.460967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸ“– | Meta Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   eeg_id    spec_id  offset  patient_id target  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote        kl\n",
      "0  568657  789577333     0.0       20654  Other           0.0       0.0      0.25        0.0   0.166667    0.583333  4.584192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-31 18:58:32.953399: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-31 18:58:32.972363: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-31 18:58:32.972544: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-31 18:58:32.973868: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-31 18:58:32.974029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-31 18:58:32.974159: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-31 18:58:33.026122: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-31 18:58:33.026320: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-31 18:58:33.026477: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-31 18:58:33.026591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6787 MB memory:  -> device: 0, name: Quadro RTX 4000, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "HMS_PATH = '/kaggle/input/hms-harmful-brain-activity-classification'\n",
    "\n",
    "\n",
    "def add_kl(data):\n",
    "    labels = data[TARGETS].values + 1e-5\n",
    "    data['kl'] = tf.keras.losses.KLDivergence(reduction='none')(\n",
    "        np.array([[1/6]*6]*len(data)),labels)\n",
    "    return data\n",
    "\n",
    "if not submission:\n",
    "    train = pd.read_csv('../train.csv')\n",
    "    TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "    META = ['spectrogram_id','spectrogram_label_offset_seconds','patient_id','expert_consensus']\n",
    "    train = train.groupby('eeg_id')[META+TARGETS\n",
    "                           ].agg({**{m:'first' for m in META},**{t:'sum' for t in TARGETS}}).reset_index() \n",
    "    train[TARGETS] = train[TARGETS]/train[TARGETS].values.sum(axis=1,keepdims=True)\n",
    "    train.columns = ['eeg_id','spec_id','offset','patient_id','target'] + TARGETS\n",
    "    train = add_kl(train)\n",
    "    print(train.head(1).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 234 ms, sys: 8.91 s, total: 9.14 s\n",
      "Wall time: 9.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not submission:\n",
    "    spectrograms = None\n",
    "    all_eegs = None\n",
    "    all_raw_eegs = None\n",
    "    if DATA_TYPE in ['K','KE','KR','KER', 'KERFW']:\n",
    "        spectrograms = np.load('../spectro_npy/specs.npy',allow_pickle=True).item()\n",
    "    if DATA_TYPE in ['E','KE','ER','KER', 'KERFW']:\n",
    "        all_eegs = np.load('../eeg_spectro_npy/eeg_specs.npy',allow_pickle=True).item()\n",
    "    if DATA_TYPE in ['R','KR','ER','KER', 'KERFW']:\n",
    "        if USE_PROCESSED:\n",
    "            all_raw_eegs = np.load('../eeg_npy/eegs_processed.npy',allow_pickle=True).item()\n",
    "        else:\n",
    "            all_raw_eegs = np.load('../eeg_npy/eegs.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_augmenter(dim=CFG.image_size):\n",
    "    augmenters = [\n",
    "        keras_cv.layers.MixUp(alpha=2.0),\n",
    "        keras_cv.layers.RandomCutout(height_factor=(1.0, 1.0),\n",
    "                                     width_factor=(0.06, 0.1)), # freq-masking\n",
    "        keras_cv.layers.RandomCutout(height_factor=(0.06, 0.1),\n",
    "                                     width_factor=(1.0, 1.0)), # time-masking\n",
    "    ]    \n",
    "    return augmenters\n",
    "\n",
    "augmenters = build_augmenter()\n",
    "def augment( data , augmenters= augmenters):\n",
    "    for a in augmenters:\n",
    "        data = a(data)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.fft import fft\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from skimage.transform import rescale, resize\n",
    "\n",
    "import librosa\n",
    "    \n",
    "FEATS2 = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n",
    "FEAT2IDX = {x:y for x,y in zip(FEATS2,range(len(FEATS2)))}\n",
    "FEATS = [['Fp1','F7','T3','T5','O1'],\n",
    "         ['Fp1','F3','C3','P3','O1'],\n",
    "         ['Fp2','F8','T4','T6','O2'],\n",
    "         ['Fp2','F4','C4','P4','O2']]\n",
    "import warnings\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    class DataGenerator(Sequence):\n",
    "        'Generates data for Keras'\n",
    "        def __init__(self, data, specs=None, eeg_specs=None, raw_eegs=None , augment=False, visualize = False, mode='train', data_type=DATA_TYPE): \n",
    "            self.data = data\n",
    "            self.augment = augment\n",
    "            self.mode = mode\n",
    "            self.data_type = data_type\n",
    "            self.specs = specs\n",
    "            self.eeg_specs = eeg_specs\n",
    "            self.raw_eegs = raw_eegs\n",
    "            self.visualize = visualize\n",
    "            self.on_epoch_end()\n",
    "            \n",
    "        def __len__(self):\n",
    "            return self.data.shape[0]\n",
    "    \n",
    "        def __getitem__(self, index):\n",
    "            X, y = self.data_generation(index)\n",
    "            if self.augment: X = self.augmentation(X)\n",
    "            return X, y\n",
    "        \n",
    "        def __call__(self):\n",
    "            for i in range(self.__len__()):\n",
    "                yield self.__getitem__(i)\n",
    "                \n",
    "                if i == self.__len__()-1:\n",
    "                    self.on_epoch_end()\n",
    "                    \n",
    "        def on_epoch_end(self):\n",
    "            if self.mode=='train': \n",
    "                self.data = self.data.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "        def data_generation(self, index):\n",
    "            if self.data_type == 'KE':\n",
    "                X,y = self.generate_all_specs(index)\n",
    "            elif self.data_type == 'E' or self.data_type == 'K':\n",
    "                X,y = self.generate_specs(index)\n",
    "            elif self.data_type == 'R':\n",
    "                X,y = self.generate_raw(index)\n",
    "            elif self.data_type in ['ER','KR']:\n",
    "                X1,y = self.generate_specs(index)\n",
    "                X2,y = self.generate_raw(index)\n",
    "                X = (X1,X2)\n",
    "            elif self.data_type in ['KER']:\n",
    "                X1,y = self.generate_all_specs(index)\n",
    "                X2,y = self.generate_raw(index)\n",
    "                X = (X1,X2)\n",
    "            elif self.data_type in ['KERFW']:\n",
    "                \n",
    "                X1,y = self.generate_all_specs(index)\n",
    "                X2,y = self.generate_raw(index)\n",
    "                X3,y = self.generate_fft(index)\n",
    "                X4,y = self.generate_wavelet(index)\n",
    "                #X = (X1 ,  X2 ,  X3 , X4 )\n",
    "                X = (np.expand_dims(X1,axis=0) ,  X3 , np.expand_dims(X4,axis=0) )\n",
    "            return X,np.expand_dims(y,axis =0)\n",
    "        \n",
    "        def generate_all_specs(self, index):\n",
    "            X = np.zeros((512,512,3),dtype='float32')\n",
    "            y = np.zeros((6,),dtype='float32')\n",
    "            \n",
    "            row = self.data.iloc[index]\n",
    "            if self.mode=='test': \n",
    "                offset = 0\n",
    "            else:\n",
    "                offset = int(row.offset/2)\n",
    "            \n",
    "            eeg = self.eeg_specs[row.eeg_id]\n",
    "            spec = self.specs[row.spec_id]\n",
    "            \n",
    "            imgs = [spec[offset:offset+300,k*100:(k+1)*100].T for k in [0,2,1,3]] # to match kaggle with eeg\n",
    "            img = np.stack(imgs,axis=-1)\n",
    "            # LOG TRANSFORM SPECTROGRAM\n",
    "            img = np.clip(img,np.exp(-4),np.exp(8))\n",
    "            img = np.log(img)\n",
    "                \n",
    "            # STANDARDIZE PER IMAGE\n",
    "            img = np.nan_to_num(img, nan=0.0)    \n",
    "                \n",
    "            mn = img.flatten().min()\n",
    "            mx = img.flatten().max()\n",
    "            ep = 1e-5\n",
    "            img = 255 * (img - mn) / (mx - mn + ep)\n",
    "            \n",
    "            X[0_0+56:100+56,:256,0] = img[:,22:-22,0] # LL_k\n",
    "            X[100+56:200+56,:256,0] = img[:,22:-22,2] # RL_k\n",
    "            X[0_0+56:100+56,:256,1] = img[:,22:-22,1] # LP_k\n",
    "            X[100+56:200+56,:256,1] = img[:,22:-22,3] # RP_k\n",
    "            X[0_0+56:100+56,:256,2] = img[:,22:-22,2] # RL_k\n",
    "            X[100+56:200+56,:256,2] = img[:,22:-22,1] # LP_k\n",
    "            \n",
    "            X[0_0+56:100+56,256:,0] = img[:,22:-22,0] # LL_k\n",
    "            X[100+56:200+56,256:,0] = img[:,22:-22,2] # RL_k\n",
    "            X[0_0+56:100+56,256:,1] = img[:,22:-22,1] # LP_k\n",
    "            X[100+56:200+56,256:,1] = img[:,22:-22,3] # RP_K\n",
    "            \n",
    "            # EEG\n",
    "            img = eeg\n",
    "            mn = img.flatten().min()\n",
    "            mx = img.flatten().max()\n",
    "            ep = 1e-5\n",
    "            img = 255 * (img - mn) / (mx - mn + ep)\n",
    "            X[200+56:300+56,:256,0] = img[:,22:-22,0] # LL_e\n",
    "            X[300+56:400+56,:256,0] = img[:,22:-22,2] # RL_e\n",
    "            X[200+56:300+56,:256,1] = img[:,22:-22,1] # LP_e\n",
    "            X[300+56:400+56,:256,1] = img[:,22:-22,3] # RP_e\n",
    "            X[200+56:300+56,:256,2] = img[:,22:-22,2] # RL_e\n",
    "            X[300+56:400+56,:256,2] = img[:,22:-22,1] # LP_e\n",
    "            \n",
    "            X[200+56:300+56,256:,0] = img[:,22:-22,0] # LL_e\n",
    "            X[300+56:400+56,256:,0] = img[:,22:-22,2] # RL_e\n",
    "            X[200+56:300+56,256:,1] = img[:,22:-22,1] # LP_e\n",
    "            X[300+56:400+56,256:,1] = img[:,22:-22,3] # RP_e\n",
    "    \n",
    "            if self.mode!='test':\n",
    "                y[:] = row[TARGETS]\n",
    "            \n",
    "            return X,y\n",
    "        \n",
    "        def generate_specs(self, index):\n",
    "            X = np.zeros((512,512,3),dtype='float32')\n",
    "            y = np.zeros((6,),dtype='float32')\n",
    "            \n",
    "            row = self.data.iloc[index]\n",
    "            if self.mode=='test': \n",
    "                offset = 0\n",
    "            else:\n",
    "                offset = int(row.offset/2)\n",
    "                \n",
    "            if self.data_type in ['E','ER']:\n",
    "                img = self.eeg_specs[row.eeg_id]\n",
    "            elif self.data_type in ['K','KR']:\n",
    "                spec = self.specs[row.spec_id]\n",
    "                imgs = [spec[offset:offset+300,k*100:(k+1)*100].T for k in [0,2,1,3]] # to match kaggle with eeg\n",
    "                img = np.stack(imgs,axis=-1)\n",
    "                # LOG TRANSFORM SPECTROGRAM\n",
    "                img = np.clip(img,np.exp(-4),np.exp(8))\n",
    "                img = np.log(img)\n",
    "                \n",
    "                # STANDARDIZE PER IMAGE\n",
    "                img = np.nan_to_num(img, nan=0.0)    \n",
    "                \n",
    "            mn = img.flatten().min()\n",
    "            mx = img.flatten().max()\n",
    "            ep = 1e-5\n",
    "            img = 255 * (img - mn) / (mx - mn + ep)\n",
    "            \n",
    "            X[0_0+56:100+56,:256,0] = img[:,22:-22,0]\n",
    "            X[100+56:200+56,:256,0] = img[:,22:-22,2]\n",
    "            X[0_0+56:100+56,:256,1] = img[:,22:-22,1]\n",
    "            X[100+56:200+56,:256,1] = img[:,22:-22,3]\n",
    "            X[0_0+56:100+56,:256,2] = img[:,22:-22,2]\n",
    "            X[100+56:200+56,:256,2] = img[:,22:-22,1]\n",
    "            \n",
    "            X[0_0+56:100+56,256:,0] = img[:,22:-22,0]\n",
    "            X[100+56:200+56,256:,0] = img[:,22:-22,1]\n",
    "            X[0_0+56:100+56,256:,1] = img[:,22:-22,2]\n",
    "            X[100+56:200+56,256:,1] = img[:,22:-22,3]\n",
    "            \n",
    "            X[200+56:300+56,:256,0] = img[:,22:-22,0]\n",
    "            X[300+56:400+56,:256,0] = img[:,22:-22,1]\n",
    "            X[200+56:300+56,:256,1] = img[:,22:-22,2]\n",
    "            X[300+56:400+56,:256,1] = img[:,22:-22,3]\n",
    "            X[200+56:300+56,:256,2] = img[:,22:-22,3]\n",
    "            X[300+56:400+56,:256,2] = img[:,22:-22,2]\n",
    "            \n",
    "            X[200+56:300+56,256:,0] = img[:,22:-22,0]\n",
    "            X[300+56:400+56,256:,0] = img[:,22:-22,2]\n",
    "            X[200+56:300+56,256:,1] = img[:,22:-22,1]\n",
    "            X[300+56:400+56,256:,1] = img[:,22:-22,3]\n",
    "            \n",
    "            if self.mode!='test':\n",
    "                y[:] = row[TARGETS]\n",
    "            \n",
    "            return X,y\n",
    "    \n",
    "        \n",
    "        \n",
    "        def generate_raw(self,index):\n",
    "            if USE_PROCESSED and self.mode!='test':\n",
    "                X = np.zeros((2_000,8),dtype='float32')\n",
    "                y = np.zeros((6,),dtype='float32')\n",
    "                row = self.data.iloc[index]\n",
    "                X = self.raw_eegs[row.eeg_id]\n",
    "                y[:] = row[TARGETS]\n",
    "                return X,y\n",
    "            \n",
    "            X = np.zeros((10_000,8),dtype='float32')\n",
    "            y = np.zeros((6,),dtype='float32')\n",
    "            \n",
    "            row = self.data.iloc[index]\n",
    "            eeg = self.raw_eegs[row.eeg_id]\n",
    "                \n",
    "            # FEATURE ENGINEER\n",
    "            X[:,0] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['T3']]\n",
    "            X[:,1] = eeg[:,FEAT2IDX['T3']] - eeg[:,FEAT2IDX['O1']]\n",
    "                \n",
    "            X[:,2] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['C3']]\n",
    "            X[:,3] = eeg[:,FEAT2IDX['C3']] - eeg[:,FEAT2IDX['O1']]\n",
    "                \n",
    "            X[:,4] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['C4']]\n",
    "            X[:,5] = eeg[:,FEAT2IDX['C4']] - eeg[:,FEAT2IDX['O2']]\n",
    "                \n",
    "            X[:,6] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['T4']]\n",
    "            X[:,7] = eeg[:,FEAT2IDX['T4']] - eeg[:,FEAT2IDX['O2']]\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            # STANDARDIZE\n",
    "            X = np.clip(X,-1024,1024)\n",
    "            X = np.nan_to_num(X, nan=0) / 32.0\n",
    "                \n",
    "            # BUTTER LOW-PASS FILTER\n",
    "            X = self.butter_lowpass_filter(X)\n",
    "            # Downsample\n",
    "            X = X[::5,:]\n",
    "            \n",
    "            if self.mode!='test':\n",
    "                y[:] = row[TARGETS]\n",
    "                    \n",
    "            return X,y\n",
    "    \n",
    "        def generate_fft(self,index,cutoff= 1000 ):\n",
    "            if USE_PROCESSED and self.mode!='test':\n",
    "                X = np.zeros((2_000,8),dtype='float32')\n",
    "                y = np.zeros((6,),dtype='float32')\n",
    "                row = self.data.iloc[index]\n",
    "                X = self.raw_eegs[row.eeg_id]\n",
    "                y[:] = row[TARGETS]\n",
    "            else:        \n",
    "                X = np.zeros((10_000,8),dtype='float32')\n",
    "                y = np.zeros((6,),dtype='float32')\n",
    "            \n",
    "            row = self.data.iloc[index]\n",
    "            eeg = self.raw_eegs[row.eeg_id]\n",
    "                \n",
    "            # FEATURE ENGINEER\n",
    "            X[:,0] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['T3']]\n",
    "            X[:,1] = eeg[:,FEAT2IDX['T3']] - eeg[:,FEAT2IDX['O1']]\n",
    "            \n",
    "            X[:,2] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['C3']]\n",
    "            X[:,3] = eeg[:,FEAT2IDX['C3']] - eeg[:,FEAT2IDX['O1']]\n",
    "                \n",
    "            X[:,4] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['C4']]\n",
    "            X[:,5] = eeg[:,FEAT2IDX['C4']] - eeg[:,FEAT2IDX['O2']]\n",
    "                \n",
    "            X[:,6] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['T4']]\n",
    "            X[:,7] = eeg[:,FEAT2IDX['T4']] - eeg[:,FEAT2IDX['O2']]\n",
    "                \n",
    "            # STANDARDIZE\n",
    "            X = np.clip(X,-1024,1024)\n",
    "            X = np.nan_to_num(X, nan=0) / 32.0\n",
    "    \n",
    "            if self.visualize == True:\n",
    "                # fft and split to real and imaginary\n",
    "                X =  np.vstack([ fft( X[:cutoff , i] )  for i in range( X.shape[1] ) ] )\n",
    "            else:\n",
    "                X =  np.hstack([ fft( X[:cutoff , i] )  for i in range( X.shape[1] ) ] )\n",
    "            X = np.hstack( [X.real ,  np.real(X.imag) ])\n",
    "\n",
    "            \n",
    "            if self.mode!='test':\n",
    "                y[:] = row[TARGETS]\n",
    "            if self.visualize == False:\n",
    "                X = np.expand_dims(X, axis= 0)\n",
    "            return X,y\n",
    "        \n",
    "        def generate_wavelet(self,index, cutoff= 1000 , start = 1 , stop=500, step = 10 , wavelet = signal.ricker):\n",
    "            if USE_PROCESSED and self.mode!='test':\n",
    "                X = np.zeros((2_000,8),dtype='float32')\n",
    "                y = np.zeros((6,),dtype='float32')\n",
    "                row = self.data.iloc[index]\n",
    "                X = self.raw_eegs[row.eeg_id]\n",
    "                y[:] = row[TARGETS]\n",
    "            else:\n",
    "                X = np.zeros((10_000,8),dtype='float32')\n",
    "                y = np.zeros((6,),dtype='float32')\n",
    "            \n",
    "            row = self.data.iloc[index]\n",
    "            eeg = self.raw_eegs[row.eeg_id]\n",
    "    \n",
    "            # FEATURE ENGINEER\n",
    "            X[:,0] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['T3']]\n",
    "            X[:,1] = eeg[:,FEAT2IDX['T3']] - eeg[:,FEAT2IDX['O1']]\n",
    "                \n",
    "            X[:,2] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['C3']]\n",
    "            X[:,3] = eeg[:,FEAT2IDX['C3']] - eeg[:,FEAT2IDX['O1']]\n",
    "                \n",
    "            X[:,4] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['C4']]\n",
    "            X[:,5] = eeg[:,FEAT2IDX['C4']] - eeg[:,FEAT2IDX['O2']]\n",
    "                \n",
    "            X[:,6] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['T4']]\n",
    "            X[:,7] = eeg[:,FEAT2IDX['T4']] - eeg[:,FEAT2IDX['O2']]\n",
    "    \n",
    "            # STANDARDIZE\n",
    "            X = np.clip(X,-1024,1024)\n",
    "            X = np.nan_to_num(X, nan=0) / 32.0\n",
    "    \n",
    "            # wavelet and make a downsampled image\n",
    "            widths = np.arange(start,stop )\n",
    "            cwtmatr = np.vstack( [  signal.cwt( X[:, i] , wavelet = wavelet, widths= widths) for i in range( X.shape[1] )  ]   )\n",
    "            cwtmatr = rescale(cwtmatr, 0.25, anti_aliasing=True)\n",
    "\n",
    "            cwtmatr = np.dstack([ cwtmatr, cwtmatr ,cwtmatr ])\n",
    "            \n",
    "            X = cwtmatr\n",
    "\n",
    "\n",
    "            if self.mode!='test':\n",
    "                y[:] = row[TARGETS]\n",
    "            return X,y\n",
    "            \n",
    "        def butter_lowpass_filter(self, data, cutoff_freq=20, sampling_rate=200, order=4):\n",
    "            nyquist = 0.5 * sampling_rate\n",
    "            normal_cutoff = cutoff_freq / nyquist\n",
    "            b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "            filtered_data = lfilter(b, a, data, axis=0)\n",
    "            return filtered_data\n",
    "        \n",
    "        def resize(self, img,size):\n",
    "            composition = albu.Compose([\n",
    "                    albu.Resize(size[0],size[1])\n",
    "                ])\n",
    "            return composition(image=img)['image']\n",
    "                \n",
    "        def augmentation(self, img):\n",
    "    \n",
    "            #add keras cv aug here\n",
    "            \n",
    "            composition = albu.Compose([\n",
    "                    albu.HorizontalFlip(p=0.4)\n",
    "                ])\n",
    "            return composition(image=img)['image']\n",
    "            \n",
    "    def spectrogram_from_eeg(parquet_path):\n",
    "        # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n",
    "        eeg = pd.read_parquet(parquet_path)\n",
    "        middle = (len(eeg)-10_000)//2\n",
    "        eeg = eeg.iloc[middle:middle+10_000]\n",
    "        \n",
    "        # VARIABLE TO HOLD SPECTROGRAM\n",
    "        img = np.zeros((100,300,4),dtype='float32')\n",
    "        for k in range(4):\n",
    "            COLS = FEATS[k]\n",
    "            \n",
    "            for kk in range(4):\n",
    "                # FILL NANS\n",
    "                x1 = eeg[COLS[kk]].values\n",
    "                x2 = eeg[COLS[kk+1]].values\n",
    "                m = np.nanmean(x1)\n",
    "                if np.isnan(x1).mean()<1: x1 = np.nan_to_num(x1,nan=m)\n",
    "                else: x1[:] = 0\n",
    "                m = np.nanmean(x2)\n",
    "                if np.isnan(x2).mean()<1: x2 = np.nan_to_num(x2,nan=m)\n",
    "                else: x2[:] = 0\n",
    "                    \n",
    "                # COMPUTE PAIR DIFFERENCES\n",
    "                x = x1 - x2\n",
    "    \n",
    "                # RAW SPECTROGRAM\n",
    "                mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//300, \n",
    "                      n_fft=1024, n_mels=100, fmin=0, fmax=20, win_length=128)\n",
    "                \n",
    "                # LOG TRANSFORM\n",
    "                width = (mel_spec.shape[1]//30)*30\n",
    "                mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n",
    "                img[:,:,k] += mel_spec_db\n",
    "                    \n",
    "            # AVERAGE THE 4 MONTAGE DIFFERENCES\n",
    "            img[:,:,k] /= 4.0\n",
    "              \n",
    "        return img\n",
    "    \n",
    "    def eeg_from_parquet(parquet_path):\n",
    "    \n",
    "        eeg = pd.read_parquet(parquet_path, columns=FEATS2)\n",
    "        rows = len(eeg)\n",
    "        offset = (rows-10_000)//2\n",
    "        eeg = eeg.iloc[offset:offset+10_000]\n",
    "        data = np.zeros((10_000,len(FEATS2)))\n",
    "        for j,col in enumerate(FEATS2):\n",
    "            \n",
    "            # FILL NAN\n",
    "            x = eeg[col].values.astype('float32')\n",
    "            m = np.nanmean(x)\n",
    "            if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n",
    "            else: x[:] = 0\n",
    "            \n",
    "            data[:,j] = x\n",
    "    \n",
    "        return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 512, 3)\n",
      "(8, 2000)\n",
      "(1, 998, 500, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (2000,) and (8,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m j\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m: offset \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m x1[:,j]\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m---> 25\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2_000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeature \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mj\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     offset \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m x1[:,j]\u001b[38;5;241m.\u001b[39mmax()\n\u001b[1;32m     27\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_gpu/lib/python3.8/site-packages/matplotlib/pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2814\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_gpu/lib/python3.8/site-packages/matplotlib/axes/_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1688\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_gpu/lib/python3.8/site-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_gpu/lib/python3.8/site-packages/matplotlib/axes/_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (2000,) and (8,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not submission: \n",
    "    params = {'specs':spectrograms, 'eeg_specs':all_eegs, 'raw_eegs':all_raw_eegs }\n",
    "    gen = DataGenerator(train, augment=False, visualize = True, **params)\n",
    "    \n",
    "    for x,y in gen:\n",
    "        break\n",
    "\n",
    "    for mat in x:\n",
    "        print(mat.shape)\n",
    "    \n",
    "    if DATA_TYPE in ['E','K','KE','KR','ER','KER' , 'KERFW']:\n",
    "        x1 = x[0] if DATA_TYPE in ['KR','ER','KER' ,'KERFW'] else x\n",
    "        plt.imshow(x1[:,:,0])\n",
    "        plt.title(f'Target = {y.round(1)}',size=12)\n",
    "        plt.yticks([])\n",
    "        plt.ylabel('Frequencies (Hz)',size=12)\n",
    "        plt.xlabel('Time (sec)',size=12)\n",
    "    \n",
    "    if DATA_TYPE in ['R','KR','ER','KER',  'KERFW' ]:\n",
    "        x1 = x[1] if DATA_TYPE in ['KR','ER','KER',  'KERFW' ] else x\n",
    "        plt.figure(figsize=(20,4))\n",
    "        offset = 0\n",
    "        for j in range(x1.shape[-1]):\n",
    "            if j!=0: offset -= x1[:,j].min()\n",
    "            plt.plot(range(2_000),x1[:,j]+offset,label=f'feature {j+1}')\n",
    "            offset += x1[:,j].max()\n",
    "        plt.legend()\n",
    "        \n",
    "    if DATA_TYPE in [  'KERFW' ]:\n",
    "        x1 = x[3] if DATA_TYPE in ['KERFW'] else x\n",
    "        \n",
    "        print(x1.shape)\n",
    "        plt.figure(figsize=(20,20))\n",
    "        plt.imshow(x1)\n",
    "        plt.title(f'Target = {y.round(1)}',size=12)\n",
    "        plt.yticks([])\n",
    "        plt.ylabel('Frequencies (Hz)',size=12)\n",
    "        plt.xlabel('Time (sec)',size=12)\n",
    "        plt.legend()\n",
    "\n",
    "    if DATA_TYPE in [  'KERFW' ]:\n",
    "        x1 = x[2] if DATA_TYPE in ['KERFW'] else x\n",
    "        plt.figure(figsize=(10,20))\n",
    "        \n",
    "        for row in range(x1.shape[0]):     \n",
    "            plt.plot(x1[row,:])\n",
    "        plt.title(f'Target = {y.round(1)}',size=12)\n",
    "        plt.yticks([])\n",
    "        plt.ylabel('Amplitude',size=12)\n",
    "        plt.xlabel('Frequencies (Hz)',size=12)\n",
    "        plt.legend()\n",
    "\n",
    "        \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = DataGenerator(train, visualize = False, augment=False, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.DataGenerator object at 0x7ff263d54b20>\n",
      "[(1, 512, 512, 3), (1, 16000), (1, 998, 500, 3)]\n",
      "[[0.         0.         0.         0.6666667  0.33333334 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(gen)\n",
    "for x,y in gen:\n",
    "    break\n",
    "print( [ xn.shape for xn in x ] )\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–                                                                      | 1000/17089 [23:40<6:20:57,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "X1 , X2 , X3 = [] , [] , []\n",
    "Y = []\n",
    "toydata = 1000\n",
    "\n",
    "for x,y in tqdm.tqdm(gen):\n",
    "    x1, x2 , x3   = x\n",
    "    Y.append(y)\n",
    "    X1.append(x1)\n",
    "    X2.append(x2)\n",
    "    X3.append(x3)\n",
    "    if toydata is not None:\n",
    "        if len(Y) > toydata:\n",
    "            break\n",
    "for var in [X1, X2, X3, Y]:\n",
    "    var = np.vstack(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataset\n",
    "import pickle\n",
    "with open('toyadata.pkl' , 'wb') as toyout:\n",
    "    toyout.write(pickle.dumps([X1, X2, X3, Y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('toyadata.pkl' , 'rb') as toyout:\n",
    "    X1, X2, X3, Y = pickle.loads(toyout.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 512, 512, 3)\n",
      "(1001, 16000)\n",
      "(1001, 998, 500, 3)\n",
      "(1001, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "variables = []\n",
    "for var in [X1, X2, X3, Y]:\n",
    "    var = np.vstack(var)\n",
    "    print(var.shape)\n",
    "    variables.append(var)\n",
    "X1, X2, X3, Y = variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-31 20:25:03.915660: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-31 20:25:04.044817: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndef build_model():\\n    K.clear_session()\\n    with strategy.scope():\\n        if DATA_TYPE in [\\'R\\']:\\n            model = build_wave_model()\\n        elif DATA_TYPE in [\\'K\\',\\'E\\',\\'KE\\']:\\n            model = build_spec_model()\\n        elif DATA_TYPE in [\\'KR\\',\\'ER\\',\\'KER\\']:\\n            model = build_hybrid_model()\\n    return model\\n\\ndef build_spec_model(hybrid=False):  \\n    inp = tf.keras.layers.Input((512,512,3))\\n    base_model = load_model(f\\'{LOAD_BACKBONE_FROM}\\')    \\n    x = base_model(inp)\\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\\n    if not hybrid:\\n        x = tf.keras.layers.Dense(6,activation=\\'softmax\\', dtype=\\'float32\\')(x)\\n    model = tf.keras.Model(inputs=inp, outputs=x)\\n    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\\n    loss = tf.keras.losses.KLDivergence()\\n    model.compile(loss=loss, optimizer=opt)  \\n    return model\\n\\ndef wave_block(x, filters, kernel_size, n):\\n    dilation_rates = [2**i for i in range(n)]\\n    x = Conv1D(filters = filters,\\n               kernel_size = 1,\\n               padding = \\'same\\')(x)\\n    res_x = x\\n    for dilation_rate in dilation_rates:\\n        tanh_out = Conv1D(filters = filters,\\n                          kernel_size = kernel_size,\\n                          padding = \\'same\\', \\n                          activation = \\'tanh\\', \\n                          dilation_rate = dilation_rate)(x)\\n        sigm_out = Conv1D(filters = filters,\\n                          kernel_size = kernel_size,\\n                          padding = \\'same\\',\\n                          activation = \\'sigmoid\\', \\n                          dilation_rate = dilation_rate)(x)\\n        x = Multiply()([tanh_out, sigm_out])\\n        x = Conv1D(filters = filters,\\n                   kernel_size = 1,\\n                   padding = \\'same\\')(x)\\n        res_x = Add()([res_x, x])\\n    return res_x\\n\\ndef build_wave_model(hybrid=False):\\n        \\n    # INPUT \\n    inp = tf.keras.Input(shape=(2_000,8))\\n    \\n    ############\\n    # FEATURE EXTRACTION SUB MODEL\\n    inp2 = tf.keras.Input(shape=(2_000,1))\\n    x = wave_block(inp2, 8, 4, 6)\\n    x = wave_block(x, 16, 4, 6)\\n    x = wave_block(x, 32, 4, 6)\\n    x = wave_block(x, 64, 4, 6)\\n    model2 = tf.keras.Model(inputs=inp2, outputs=x)\\n    ###########\\n    \\n    # LEFT TEMPORAL CHAIN\\n    x1 = model2(inp[:,:,0:1])\\n    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\\n    x2 = model2(inp[:,:,1:2])\\n    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\\n    z1 = tf.keras.layers.Average()([x1,x2])\\n    \\n    # LEFT PARASAGITTAL CHAIN\\n    x1 = model2(inp[:,:,2:3])\\n    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\\n    x2 = model2(inp[:,:,3:4])\\n    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\\n    z2 = tf.keras.layers.Average()([x1,x2])\\n    \\n    # RIGHT PARASAGITTAL CHAIN\\n    x1 = model2(inp[:,:,4:5])\\n    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\\n    x2 = model2(inp[:,:,5:6])\\n    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\\n    z3 = tf.keras.layers.Average()([x1,x2])\\n    \\n    # RIGHT TEMPORAL CHAIN\\n    x1 = model2(inp[:,:,6:7])\\n    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\\n    x2 = model2(inp[:,:,7:8])\\n    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\\n    z4 = tf.keras.layers.Average()([x1,x2])\\n    \\n    # COMBINE CHAINS\\n    y = tf.keras.layers.Concatenate()([z1,z2,z3,z4])\\n    if not hybrid:\\n        y = tf.keras.layers.Dense(64, activation=\\'relu\\')(y)\\n        y = tf.keras.layers.Dense(6,activation=\\'softmax\\', dtype=\\'float32\\')(y)\\n    \\n    # COMPILE MODEL\\n    model = tf.keras.Model(inputs=inp, outputs=y)\\n    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\\n    loss = tf.keras.losses.KLDivergence()\\n    model.compile(loss=loss, optimizer = opt)\\n    \\n    return model\\n\\ndef build_hybrid_model():\\n    model_spec = build_spec_model(True)\\n    model_wave = build_wave_model(True)\\n    inputs = [model_spec.input, model_wave.input]\\n    x = [model_spec.output, model_wave.output]\\n    x = tf.keras.layers.Concatenate()(x)\\n    x = tf.keras.layers.Dense(6,activation=\\'softmax\\', dtype=\\'float32\\')(x)\\n    \\n    # COMPILE MODEL\\n    model = tf.keras.Model(inputs=inputs, outputs=x)\\n    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\\n    loss = tf.keras.losses.KLDivergence()\\n    model.compile(loss=loss, optimizer = opt)\\n    \\n    return model\\n\\ndef score(y_true, y_pred):\\n    kl = tf.keras.metrics.KLDivergence()\\n    return kl(y_true, y_pred)\\n\\ndef plot_hist(hist):\\n    metrics = [\\'loss\\']\\n    for i,metric in enumerate(metrics):\\n        plt.figure(figsize=(10,4))\\n        plt.subplot(1,2,i+1)\\n        plt.plot(hist[metric])\\n        plt.plot(hist[f\\'val_{metric}\\'])\\n        plt.title(f\\'{metric}\\',size=12)\\n        plt.ylabel(f\\'{metric}\\',size=12)\\n        plt.xlabel(\\'epoch\\',size=12)\\n        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\\n        plt.show()\\n        \\ndef dataset(data, mode=\\'train\\', batch_size=8, data_type=DATA_TYPE, \\n            augment=False, specs=None, eeg_specs=None, raw_eegs=None):\\n    \\n    BATCH_SIZE_PER_REPLICA = batch_size\\n    BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\\n    gen = DataGenerator(data,mode=mode, data_type=data_type, augment=augment,\\n                       specs=specs, eeg_specs=eeg_specs, raw_eegs=raw_eegs)\\n    if data_type in [\\'K\\',\\'E\\',\\'KE\\']: \\n        inp = tf.TensorSpec(shape=(512,512,3), dtype=tf.float32)\\n    elif data_type in [\\'KR\\',\\'ER\\',\\'KER\\']:\\n        inp = (tf.TensorSpec(shape=(512,512,3), dtype=tf.float32),tf.TensorSpec(shape=(2000,8), dtype=tf.float32))\\n    elif data_type in [\\'R\\']:\\n        inp = tf.TensorSpec(shape=(2000,8), dtype=tf.float32)\\n        \\n    output_signature = (inp,tf.TensorSpec(shape=(6,), dtype=tf.float32))\\n    dataset = tf.data.Dataset.from_generator(generator=gen, output_signature=output_signature).batch(\\n        BATCH_SIZE)\\n    return dataset\\n\\ndef reset_seed(seed):\\n    np.random.seed(seed)\\n    random.seed(seed)\\n    tf.random.set_seed(seed)\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Multiply, Add, Conv1D, Concatenate, LayerNormalization\n",
    "\n",
    "\"\"\"\n",
    "def build_model():\n",
    "    K.clear_session()\n",
    "    with strategy.scope():\n",
    "        if DATA_TYPE in ['R']:\n",
    "            model = build_wave_model()\n",
    "        elif DATA_TYPE in ['K','E','KE']:\n",
    "            model = build_spec_model()\n",
    "        elif DATA_TYPE in ['KR','ER','KER']:\n",
    "            model = build_hybrid_model()\n",
    "    return model\n",
    "\n",
    "def build_spec_model(hybrid=False):  \n",
    "    inp = tf.keras.layers.Input((512,512,3))\n",
    "    base_model = load_model(f'{LOAD_BACKBONE_FROM}')    \n",
    "    x = base_model(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    if not hybrid:\n",
    "        x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n",
    "    model = tf.keras.Model(inputs=inp, outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "    model.compile(loss=loss, optimizer=opt)  \n",
    "    return model\n",
    "\n",
    "def wave_block(x, filters, kernel_size, n):\n",
    "    dilation_rates = [2**i for i in range(n)]\n",
    "    x = Conv1D(filters = filters,\n",
    "               kernel_size = 1,\n",
    "               padding = 'same')(x)\n",
    "    res_x = x\n",
    "    for dilation_rate in dilation_rates:\n",
    "        tanh_out = Conv1D(filters = filters,\n",
    "                          kernel_size = kernel_size,\n",
    "                          padding = 'same', \n",
    "                          activation = 'tanh', \n",
    "                          dilation_rate = dilation_rate)(x)\n",
    "        sigm_out = Conv1D(filters = filters,\n",
    "                          kernel_size = kernel_size,\n",
    "                          padding = 'same',\n",
    "                          activation = 'sigmoid', \n",
    "                          dilation_rate = dilation_rate)(x)\n",
    "        x = Multiply()([tanh_out, sigm_out])\n",
    "        x = Conv1D(filters = filters,\n",
    "                   kernel_size = 1,\n",
    "                   padding = 'same')(x)\n",
    "        res_x = Add()([res_x, x])\n",
    "    return res_x\n",
    "\n",
    "def build_wave_model(hybrid=False):\n",
    "        \n",
    "    # INPUT \n",
    "    inp = tf.keras.Input(shape=(2_000,8))\n",
    "    \n",
    "    ############\n",
    "    # FEATURE EXTRACTION SUB MODEL\n",
    "    inp2 = tf.keras.Input(shape=(2_000,1))\n",
    "    x = wave_block(inp2, 8, 4, 6)\n",
    "    x = wave_block(x, 16, 4, 6)\n",
    "    x = wave_block(x, 32, 4, 6)\n",
    "    x = wave_block(x, 64, 4, 6)\n",
    "    model2 = tf.keras.Model(inputs=inp2, outputs=x)\n",
    "    ###########\n",
    "    \n",
    "    # LEFT TEMPORAL CHAIN\n",
    "    x1 = model2(inp[:,:,0:1])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = model2(inp[:,:,1:2])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z1 = tf.keras.layers.Average()([x1,x2])\n",
    "    \n",
    "    # LEFT PARASAGITTAL CHAIN\n",
    "    x1 = model2(inp[:,:,2:3])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = model2(inp[:,:,3:4])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z2 = tf.keras.layers.Average()([x1,x2])\n",
    "    \n",
    "    # RIGHT PARASAGITTAL CHAIN\n",
    "    x1 = model2(inp[:,:,4:5])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = model2(inp[:,:,5:6])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z3 = tf.keras.layers.Average()([x1,x2])\n",
    "    \n",
    "    # RIGHT TEMPORAL CHAIN\n",
    "    x1 = model2(inp[:,:,6:7])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = model2(inp[:,:,7:8])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z4 = tf.keras.layers.Average()([x1,x2])\n",
    "    \n",
    "    # COMBINE CHAINS\n",
    "    y = tf.keras.layers.Concatenate()([z1,z2,z3,z4])\n",
    "    if not hybrid:\n",
    "        y = tf.keras.layers.Dense(64, activation='relu')(y)\n",
    "        y = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(y)\n",
    "    \n",
    "    # COMPILE MODEL\n",
    "    model = tf.keras.Model(inputs=inp, outputs=y)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "    model.compile(loss=loss, optimizer = opt)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_hybrid_model():\n",
    "    model_spec = build_spec_model(True)\n",
    "    model_wave = build_wave_model(True)\n",
    "    inputs = [model_spec.input, model_wave.input]\n",
    "    x = [model_spec.output, model_wave.output]\n",
    "    x = tf.keras.layers.Concatenate()(x)\n",
    "    x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    # COMPILE MODEL\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "    model.compile(loss=loss, optimizer = opt)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def score(y_true, y_pred):\n",
    "    kl = tf.keras.metrics.KLDivergence()\n",
    "    return kl(y_true, y_pred)\n",
    "\n",
    "def plot_hist(hist):\n",
    "    metrics = ['loss']\n",
    "    for i,metric in enumerate(metrics):\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.subplot(1,2,i+1)\n",
    "        plt.plot(hist[metric])\n",
    "        plt.plot(hist[f'val_{metric}'])\n",
    "        plt.title(f'{metric}',size=12)\n",
    "        plt.ylabel(f'{metric}',size=12)\n",
    "        plt.xlabel('epoch',size=12)\n",
    "        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "        plt.show()\n",
    "        \n",
    "def dataset(data, mode='train', batch_size=8, data_type=DATA_TYPE, \n",
    "            augment=False, specs=None, eeg_specs=None, raw_eegs=None):\n",
    "    \n",
    "    BATCH_SIZE_PER_REPLICA = batch_size\n",
    "    BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "    gen = DataGenerator(data,mode=mode, data_type=data_type, augment=augment,\n",
    "                       specs=specs, eeg_specs=eeg_specs, raw_eegs=raw_eegs)\n",
    "    if data_type in ['K','E','KE']: \n",
    "        inp = tf.TensorSpec(shape=(512,512,3), dtype=tf.float32)\n",
    "    elif data_type in ['KR','ER','KER']:\n",
    "        inp = (tf.TensorSpec(shape=(512,512,3), dtype=tf.float32),tf.TensorSpec(shape=(2000,8), dtype=tf.float32))\n",
    "    elif data_type in ['R']:\n",
    "        inp = tf.TensorSpec(shape=(2000,8), dtype=tf.float32)\n",
    "        \n",
    "    output_signature = (inp,tf.TensorSpec(shape=(6,), dtype=tf.float32))\n",
    "    dataset = tf.data.Dataset.from_generator(generator=gen, output_signature=output_signature).batch(\n",
    "        BATCH_SIZE)\n",
    "    return dataset\n",
    "\n",
    "def reset_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmoi/miniconda3/envs/tf_gpu/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-31 20:25:07.536401: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-31 20:25:07.655773: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-31 20:25:07.656118: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-31 20:25:07.658655: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-31 20:25:07.658979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-31 20:25:07.659282: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-31 20:25:07.723903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-31 20:25:07.724278: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-31 20:25:07.724420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-31 20:25:07.724529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6787 MB memory:  -> device: 0, name: Quadro RTX 4000, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense , BatchNormalization , Input ,GlobalAveragePooling2D , Flatten\n",
    "from keras.losses import KLDivergence\n",
    "from keras import Model\n",
    "import keras_cv\n",
    "import keras\n",
    "\n",
    "def wave_block(x, filters, kernel_size, n):\n",
    "    dilation_rates = [2**i for i in range(n)]\n",
    "    x = Conv1D(filters = filters,\n",
    "               kernel_size = 1,\n",
    "               padding = 'same')(x)\n",
    "    res_x = x\n",
    "    for dilation_rate in dilation_rates:\n",
    "        tanh_out = Conv1D(filters = filters,\n",
    "                          kernel_size = kernel_size,\n",
    "                          padding = 'same', \n",
    "                          activation = 'tanh', \n",
    "                          dilation_rate = dilation_rate)(x)\n",
    "        sigm_out = Conv1D(filters = filters,\n",
    "                          kernel_size = kernel_size,\n",
    "                          padding = 'same',\n",
    "                          activation = 'sigmoid', \n",
    "                          dilation_rate = dilation_rate)(x)\n",
    "        x = Multiply()([tanh_out, sigm_out])\n",
    "        x = Conv1D(filters = filters,\n",
    "                   kernel_size = 1,\n",
    "                   padding = 'same')(x)\n",
    "        res_x = Add()([res_x, x])\n",
    "    return res_x\n",
    "\n",
    "modelspec = keras_cv.models.ImageClassifier.from_preset(\n",
    "    \"csp_darknet_tiny\",num_classes = 6\n",
    ")\n",
    "\n",
    "def resnet_block(x):\n",
    "    modelspec = keras_cv.models.ImageClassifier.from_preset(\n",
    "        \"csp_darknet_tiny\",num_classes = 6\n",
    "    )\n",
    "    modelspec_out = modelspec.layers[-2].output  # This gets the layer before the output layer\n",
    "    xspec = Dense(1024, activation='relu')(modelspec_out)\n",
    "    model = Model(inputs=modelspec.input, outputs=modelspec_out)\n",
    "    return model(x)\n",
    "\n",
    "    \n",
    "def buildmodel( ):\n",
    "    Input_spec =  Input( (None,None, 3)  , name = 'spec')\n",
    "    Input_wav =  Input( (None, None, 3) , name = 'wav')\n",
    "    Input_fft = Input(  ( 16000 ) , name = 'fft' )\n",
    "    #Input_stats = ( ( ) , name = 'stats_in' )\n",
    "\n",
    "    #Input_fft_n = BatchNormalization()(Input_fft)\n",
    "    \n",
    "    xwav =resnet_block(Input_wav)\n",
    "    #aux0\n",
    "    aux0 = Dense( 6 , activation = 'softmax' , name = 'aux0')(xwav)\n",
    "    \n",
    "    #wavelet transform\n",
    "    xspec = resnet_block(Input_spec)\n",
    "    aux1 = Dense( 6 , activation = 'softmax')(xspec)\n",
    "\n",
    "    #dense fft \n",
    "    xfft = Dense( 500 , activation = 'tanh')(Input_fft)\n",
    "    xfft = Dense( 250 , activation = 'tanh')(xfft)\n",
    "    xfft = Dense( 250 , activation = 'tanh')(xfft)\n",
    "    \n",
    "    fftout = Dense( 10 , activation = 'tanh')(xfft)\n",
    "    aux2 = Dense( 6 , activation = 'softmax' , name= 'aux2')(xfft)\n",
    "\n",
    "\n",
    "\n",
    "    xspec = Flatten()(xspec)\n",
    "    xwav = Flatten()(xwav)\n",
    "    xfft = Flatten()(xfft)\n",
    "\n",
    "    integrate = keras.layers.Concatenate( axis = 1 )( [ xfft, xspec , xwav ] )\n",
    "\n",
    "    #integrate = Flatten()(integrate)\n",
    "    \n",
    "    integrate = Dense( 500 , activation = 'tanh')(integrate)\n",
    "    integrate = Dense( 250 , activation = 'tanh')(integrate)\n",
    "    integrate = Dense( 100 , activation = 'tanh')(integrate)\n",
    "\n",
    "    \n",
    "    #final classification\n",
    "    final = Dense( 6 , activation = 'softmax' , name= 'aux')(integrate)\n",
    "    \n",
    "    lossfun = KLDivergence( )\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=True,\n",
    "    weight_decay=10**-6,\n",
    "    clipnorm=None,\n",
    "    clipvalue=None,\n",
    "    global_clipnorm=None,\n",
    "    use_ema=True,\n",
    "    ema_momentum=0.99,\n",
    "    ema_overwrite_frequency=10,\n",
    "    name=\"adam\",\n",
    "    )\n",
    "    \n",
    "    #output\n",
    "    model = keras.Model(\n",
    "        inputs=[Input_spec,Input_fft,Input_wav], \n",
    "        outputs=[aux0, aux1, aux2, final],\n",
    "         )\n",
    "    model.compile( loss = lossfun, optimizer = optimizer , metrics=[\n",
    "        'MeanSquaredError',\n",
    "        'AUC',\n",
    "        ] ,\n",
    "        run_eagerly=True\n",
    "                 )\n",
    "    return model\n",
    "\n",
    "model = buildmodel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " fft (InputLayer)            [(None, 16000)]              0         []                            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 500)                  8000500   ['fft[0][0]']                 \n",
      "                                                                                                  \n",
      " wav (InputLayer)            [(None, None, None, 3)]      0         []                            \n",
      "                                                                                                  \n",
      " spec (InputLayer)           [(None, None, None, 3)]      0         []                            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 250)                  125250    ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " model (Functional)          (None, 384)                  2380416   ['wav[0][0]']                 \n",
      "                                                                                                  \n",
      " model_1 (Functional)        (None, 384)                  2380416   ['spec[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 250)                  62750     ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 250)                  0         ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 384)                  0         ['model_1[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 384)                  0         ['model[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenat  (None, 1018)                 0         ['flatten_2[0][0]',           \n",
      " e)                                                                  'flatten[0][0]',             \n",
      "                                                                     'flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 500)                  509500    ['concatenate_12[0][0]']      \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 250)                  125250    ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 100)                  25100     ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " aux0 (Dense)                (None, 6)                    2310      ['model[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 6)                    2310      ['model_1[0][0]']             \n",
      "                                                                                                  \n",
      " aux2 (Dense)                (None, 6)                    1506      ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " aux (Dense)                 (None, 6)                    606       ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13615914 (51.94 MB)\n",
      "Trainable params: 13599690 (51.88 MB)\n",
      "Non-trainable params: 16224 (63.38 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016209,
     "end_time": "2024-01-14T03:18:49.21924",
     "exception": false,
     "start_time": "2024-01-14T03:18:49.203031",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# âš“ | LR Schedule\n",
    "\n",
    "A well-structured learning rate schedule is essential for efficient model training, ensuring optimal convergence and avoiding issues such as overshooting or stagnation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.028945,
     "end_time": "2024-01-14T03:18:49.264535",
     "exception": false,
     "start_time": "2024-01-14T03:18:49.23559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n",
    "    lr_start, lr_max, lr_min = 5e-5, 6e-6 * batch_size, 1e-5\n",
    "    lr_ramp_ep, lr_sus_ep, lr_decay = 3, 0, 0.75\n",
    "\n",
    "    def lrfn(epoch):  # Learning rate update function\n",
    "        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n",
    "        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n",
    "        elif mode == 'cos':\n",
    "            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n",
    "            phase = math.pi * decay_epoch_index / decay_total_epochs\n",
    "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n",
    "        return lr\n",
    "\n",
    "    if plot:  # Plot lr curve if plot is True\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n",
    "        plt.xlabel('epoch'); plt.ylabel('lr')\n",
    "        plt.title('LR Scheduler')\n",
    "        plt.show()\n",
    "\n",
    "    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # Create lr callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.297147,
     "end_time": "2024-01-14T03:18:49.578089",
     "exception": false,
     "start_time": "2024-01-14T03:18:49.280942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lr_cb = get_lr_callback(CFG.batch_size, mode=CFG.lr_mode, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017199,
     "end_time": "2024-01-14T03:18:49.613648",
     "exception": false,
     "start_time": "2024-01-14T03:18:49.596449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸ’¾ | Model Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.024529,
     "end_time": "2024-01-14T03:18:49.655708",
     "exception": false,
     "start_time": "2024-01-14T03:18:49.631179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ckpt_cb = keras.callbacks.ModelCheckpoint(\"best_model.keras\",\n",
    "                                         monitor='val_loss',\n",
    "                                         save_best_only=True,\n",
    "                                         save_weights_only=False,\n",
    "                                         mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(X1[:100].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01671,
     "end_time": "2024-01-14T03:18:49.689354",
     "exception": false,
     "start_time": "2024-01-14T03:18:49.672644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸš‚ | Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 3374.692199,
     "end_time": "2024-01-14T04:15:04.398389",
     "exception": false,
     "start_time": "2024-01-14T03:18:49.70619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x = {'spec': X1[:400], 'wav': X3[:400] , 'fft': X2[:400]},\n",
    "    y = Y[:400],\n",
    "    epochs=100,\n",
    "    callbacks=[ ckpt_cb], \n",
    "    steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.693309,
     "end_time": "2024-01-14T04:15:05.731839",
     "exception": false,
     "start_time": "2024-01-14T04:15:05.03853",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸ§ª | Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.632183,
     "end_time": "2024-01-14T04:15:06.991143",
     "exception": false,
     "start_time": "2024-01-14T04:15:06.35896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T08:26:11.994508Z",
     "iopub.status.busy": "2024-01-21T08:26:11.994138Z",
     "iopub.status.idle": "2024-01-21T08:26:19.318291Z",
     "shell.execute_reply": "2024-01-21T08:26:19.317485Z",
     "shell.execute_reply.started": "2024-01-21T08:26:11.994479Z"
    },
    "papermill": {
     "duration": 20.428261,
     "end_time": "2024-01-14T04:15:28.044401",
     "exception": false,
     "start_time": "2024-01-14T04:15:07.61614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"best_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if submission:\n",
    "    test = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')\n",
    "    print('Test shape',test.shape)\n",
    "    test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ ALL SPECTROGRAMS\n",
    "if submission:\n",
    "    PATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms'\n",
    "    files2 = os.listdir(PATH2)\n",
    "    print(f'There are {len(files2)} test spectrogram parquets')\n",
    "    \n",
    "    spectrograms2 = {}\n",
    "    for i,f in enumerate(files2):\n",
    "        if i%100==0: print(i,', ',end='')\n",
    "        tmp = pd.read_parquet(f'{PATH2}/{f}')\n",
    "        name = int(f.split('.')[0])\n",
    "        spectrograms2[name] = tmp.iloc[:,1:].values\n",
    "    \n",
    "    # RENAME FOR DATA GENERATOR\n",
    "    test = test.rename({'spectrogram_id':'spec_id'},axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ ALL EEG SPECTROGRAMS\n",
    "if submission:\n",
    "    PATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs'\n",
    "    DISPLAY = 0\n",
    "    EEG_IDS2 = test.eeg_id.unique()\n",
    "    all_eegs2 = {}\n",
    "\n",
    "    print('Converting Test EEG to Spectrograms...'); print()\n",
    "    for i,eeg_id in enumerate(EEG_IDS2):\n",
    "        \n",
    "        # CREATE SPECTROGRAM FROM EEG PARQUET\n",
    "        img = spectrogram_from_eeg(f'{PATH2}/{eeg_id}.parquet')\n",
    "        all_eegs2[eeg_id] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ ALL RAW EEG SIGNALS\n",
    "if submission :\n",
    "    all_raw_eegs2 = {}\n",
    "    EEG_IDS2 = test.eeg_id.unique()\n",
    "    PATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs'\n",
    "\n",
    "    print('Processing Test EEG parquets...'); print()\n",
    "    for i,eeg_id in enumerate(EEG_IDS2):\n",
    "        \n",
    "        # SAVE EEG TO PYTHON DICTIONARY OF NUMPY ARRAYS\n",
    "        data = eeg_from_parquet(f'{PATH2}/{eeg_id}.parquet')\n",
    "        all_raw_eegs2[eeg_id] = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission ON TEST without ensemble\n",
    "if submission and not ENSEMBLE:\n",
    "    preds = []\n",
    "    \n",
    "    test_dataset = dataset(test,mode='test',specs=spectrograms2, eeg_specs=all_eegs2, raw_eegs=all_raw_eegs2)\n",
    "    model = build_model()\n",
    "\n",
    "    for i in range(5):\n",
    "        print(f'Fold {i+1}')\n",
    "        model.load_weights(f'{LOAD_MODELS_FROM}/model_{DATA_TYPE}_{VER}_{i}.weights.h5')\n",
    "        pred = model.predict(test_dataset, verbose=1)\n",
    "        preds.append(pred)\n",
    "        \n",
    "    pred = np.mean(preds,axis=0)\n",
    "    print('Test preds shape',pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission ON TEST with ensemble\n",
    "if submission and ENSEMBLE:\n",
    "    preds = []\n",
    "    params = {'specs':spectrograms2, 'eeg_specs':all_eegs2, 'raw_eegs':all_raw_eegs2}\n",
    "    test_dataset_K = dataset(test, data_type='K', mode='test', **params)\n",
    "    test_dataset_E = dataset(test, data_type='E', mode='test', **params)\n",
    "    test_dataset_R = dataset(test, data_type='R', mode='test', **params)\n",
    "    test_dataset_KE = dataset(test, data_type='KE', mode='test', **params)\n",
    "    test_dataset_KR = dataset(test, data_type='KR', mode='test', **params)\n",
    "    test_dataset_ER = dataset(test, data_type='ER', mode='test', **params)\n",
    "    test_dataset_KER = dataset(test, data_type='KER', mode='test', **params)\n",
    "\n",
    "    # LB SCORE WEIGHTS FOR EACH MODEL\n",
    "    lbs = 1 - np.array(LBs)\n",
    "    weights = lbs/lbs.sum()\n",
    "    model_spec = build_spec_model()\n",
    "    model_wave = build_wave_model()\n",
    "    model_hybrid = build_hybrid_model()\n",
    "    \n",
    "    for i in range(5):\n",
    "        print(f'Fold {i+1}')\n",
    "        \n",
    "        model_spec.load_weights(f'{LOAD_MODELS_FROM}/model_K_{VER_K}_{i}.weights.h5')\n",
    "        pred_K = model_spec.predict(test_dataset_K, verbose=1)\n",
    "        \n",
    "        model_spec.load_weights(f'{LOAD_MODELS_FROM}/model_E_{VER_E}_{i}.weights.h5')\n",
    "        pred_E = model_spec.predict(test_dataset_E, verbose=1)\n",
    "\n",
    "        model_wave.load_weights(f'{LOAD_MODELS_FROM}/model_R_{VER_R}_{i}.weights.h5')\n",
    "        pred_R = model_wave.predict(test_dataset_R, verbose=1)\n",
    "        \n",
    "        model_spec.load_weights(f'{LOAD_MODELS_FROM}/model_KE_{VER_KE}_{i}.weights.h5')\n",
    "        pred_KE = model_spec.predict(test_dataset_KE, verbose=1)\n",
    "        \n",
    "        model_hybrid.load_weights(f'{LOAD_MODELS_FROM}/model_KR_{VER_KR}_{i}.weights.h5')\n",
    "        pred_KR = model_hybrid.predict(test_dataset_KR, verbose=1)\n",
    "        \n",
    "        model_hybrid.load_weights(f'{LOAD_MODELS_FROM}/model_ER_{VER_ER}_{i}.weights.h5')\n",
    "        pred_ER = model_hybrid.predict(test_dataset_ER, verbose=1)\n",
    "        \n",
    "        model_hybrid.load_weights(f'{LOAD_MODELS_FROM}/model_KER_{VER_KER}_{i}.weights.h5')\n",
    "        pred_KER = model_hybrid.predict(test_dataset_KER, verbose=1)\n",
    "        \n",
    "        pred = np.array([pred_K,pred_E,pred_R,pred_KE,pred_KR,pred_ER,pred_KER])\n",
    "        pred = np.average(pred,axis=0,weights=weights)\n",
    "        preds.append(pred)\n",
    "        \n",
    "    pred = np.mean(preds,axis=0)\n",
    "    print('Test preds shape',pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE\n",
    "if submission:\n",
    "    print(sub.iloc[:,-6:].sum(axis=1).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.703901,
     "end_time": "2024-01-14T04:20:09.745279",
     "exception": false,
     "start_time": "2024-01-14T04:20:09.041378",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Build Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T08:26:19.320511Z",
     "iopub.status.busy": "2024-01-21T08:26:19.320221Z",
     "iopub.status.idle": "2024-01-21T08:26:19.366196Z",
     "shell.execute_reply": "2024-01-21T08:26:19.365433Z",
     "shell.execute_reply.started": "2024-01-21T08:26:19.320486Z"
    }
   },
   "outputs": [],
   "source": [
    "test_paths = test_df.spec2_path.values\n",
    "test_ds = build_dataset(test_paths, batch_size=min(CFG.batch_size, len(test_df)),\n",
    "                         repeat=False, shuffle=False, cache=False, augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T08:26:19.367983Z",
     "iopub.status.busy": "2024-01-21T08:26:19.367379Z",
     "iopub.status.idle": "2024-01-21T08:26:44.828629Z",
     "shell.execute_reply": "2024-01-21T08:26:44.827887Z",
     "shell.execute_reply.started": "2024-01-21T08:26:19.367955Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“© | Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T08:26:44.830386Z",
     "iopub.status.busy": "2024-01-21T08:26:44.830108Z",
     "iopub.status.idle": "2024-01-21T08:26:44.873794Z",
     "shell.execute_reply": "2024-01-21T08:26:44.872998Z",
     "shell.execute_reply.started": "2024-01-21T08:26:44.830361Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_df = test_df[[\"eeg_id\"]].copy()\n",
    "target_cols = [x.lower()+'_vote' for x in CFG.class_names]\n",
    "pred_df[target_cols] = preds.tolist()\n",
    "\n",
    "sub_df = pd.read_csv(f'{BASE_PATH}/sample_submission.csv')\n",
    "sub_df = sub_df[[\"eeg_id\"]].copy()\n",
    "sub_df = sub_df.merge(pred_df, on=\"eeg_id\", how=\"left\")\n",
    "sub_df.to_csv(\"submission.csv\", index=False)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "\n",
    "import kaggle_metric_utilities\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def kl_divergence(solution: pd.DataFrame, submission: pd.DataFrame, epsilon: float, micro_average: bool, sample_weights: Optional[pd.Series]):\n",
    "    # Overwrite solution for convenience\n",
    "    for col in solution.columns:\n",
    "        # Prevent issue with populating int columns with floats\n",
    "        if not pandas.api.types.is_float_dtype(solution[col]):\n",
    "            solution[col] = solution[col].astype(float)\n",
    "\n",
    "        # Clip both the min and max following Kaggle conventions for related metrics like log loss\n",
    "        # Clipping the max avoids cases where the loss would be infinite or undefined, clipping the min\n",
    "        # prevents users from playing games with the 20th decimal place of predictions.\n",
    "        submission[col] = np.clip(submission[col], epsilon, 1 - epsilon)\n",
    "\n",
    "        y_nonzero_indices = solution[col] != 0\n",
    "        solution[col] = solution[col].astype(float)\n",
    "        solution.loc[y_nonzero_indices, col] = solution.loc[y_nonzero_indices, col] * np.log(solution.loc[y_nonzero_indices, col] / submission.loc[y_nonzero_indices, col])\n",
    "        # Set the loss equal to zero where y_true equals zero following the scipy convention:\n",
    "        # https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.rel_entr.html#scipy.special.rel_entr\n",
    "        solution.loc[~y_nonzero_indices, col] = 0\n",
    "\n",
    "    if micro_average:\n",
    "        return np.average(solution.sum(axis=1), weights=sample_weights)\n",
    "    else:\n",
    "        return np.average(solution.mean())\n",
    "\n",
    "\n",
    "def score(\n",
    "        solution: pd.DataFrame,\n",
    "        submission: pd.DataFrame,\n",
    "        row_id_column_name: str,\n",
    "        epsilon: float=10**-15,\n",
    "        micro_average: bool=True,\n",
    "        sample_weights_column_name: Optional[str]=None\n",
    "    ) -> float:\n",
    "    ''' The Kullbackâ€“Leibler divergence.\n",
    "    The KL divergence is technically undefined/infinite where the target equals zero.\n",
    "\n",
    "    This implementation always assigns those cases a score of zero; effectively removing them from consideration.\n",
    "    The predictions in each row must add to one so any probability assigned to a case where y == 0 reduces\n",
    "    another prediction where y > 0, so crucially there is an important indirect effect.\n",
    "\n",
    "    https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\n",
    "\n",
    "    solution: pd.DataFrame\n",
    "    submission: pd.DataFrame\n",
    "    epsilon: KL divergence is undefined for p=0 or p=1. If epsilon is not null, solution and submission probabilities are clipped to max(eps, min(1 - eps, p).\n",
    "    row_id_column_name: str\n",
    "    micro_average: bool. Row-wise average if True, column-wise average if False.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import pandas as pd\n",
    "    >>> row_id_column_name = \"id\"\n",
    "    >>> score(pd.DataFrame({'id': range(4), 'ham': [0, 1, 1, 0], 'spam': [1, 0, 0, 1]}), pd.DataFrame({'id': range(4), 'ham': [.1, .9, .8, .35], 'spam': [.9, .1, .2, .65]}), row_id_column_name=row_id_column_name)\n",
    "    0.216161...\n",
    "    >>> solution = pd.DataFrame({'id': range(3), 'ham': [0, 0.5, 0.5], 'spam': [0.1, 0.5, 0.5], 'other': [0.9, 0, 0]})\n",
    "    >>> submission = pd.DataFrame({'id': range(3), 'ham': [0, 0.5, 0.5], 'spam': [0.1, 0.5, 0.5], 'other': [0.9, 0, 0]})\n",
    "    >>> score(solution, submission, 'id')\n",
    "    0.0\n",
    "    >>> solution = pd.DataFrame({'id': range(3), 'ham': [0, 0.5, 0.5], 'spam': [0.1, 0.5, 0.5], 'other': [0.9, 0, 0]})\n",
    "    >>> submission = pd.DataFrame({'id': range(3), 'ham': [0.2, 0.3, 0.5], 'spam': [0.1, 0.5, 0.5], 'other': [0.7, 0.2, 0]})\n",
    "    >>> score(solution, submission, 'id')\n",
    "    0.160531...\n",
    "    '''\n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "\n",
    "    sample_weights = None\n",
    "    if sample_weights_column_name:\n",
    "        if sample_weights_column_name not in solution.columns:\n",
    "            raise ParticipantVisibleError(f'{sample_weights_column_name} not found in solution columns')\n",
    "        sample_weights = solution.pop(sample_weights_column_name)\n",
    "\n",
    "    if sample_weights_column_name and not micro_average:\n",
    "        raise ParticipantVisibleError('Sample weights are only valid if `micro_average` is `True`')\n",
    "\n",
    "    for col in solution.columns:\n",
    "        if col not in submission.columns:\n",
    "            raise ParticipantVisibleError(f'Missing submission column {col}')\n",
    "\n",
    "    kaggle_metric_utilities.verify_valid_probabilities(solution, 'solution')\n",
    "    kaggle_metric_utilities.verify_valid_probabilities(submission, 'submission')\n",
    "\n",
    "\n",
    "    return kaggle_metric_utilities.safe_call_score(kl_divergence, solution, submission, epsilon=epsilon, micro_average=micro_average, sample_weights=sample_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Œ | Reference\n",
    "* [HMS-HBAC: ResNet34d Baseline [Training]](https://www.kaggle.com/code/ttahara/hms-hbac-resnet34d-baseline-training) \n",
    "* [EfficientNetB2 Starter - [LB 0.57]](https://www.kaggle.com/code/cdeotte/efficientnetb2-starter-lb-0-57)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 4308295,
     "sourceId": 7526248,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 4598,
     "sourceId": 6127,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3846.080383,
   "end_time": "2024-01-14T04:20:19.064569",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-14T03:16:12.984186",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "08983a9c6aff42578980f4f7113c3ee2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4411aefc021d46d0ada7b645eb53ec48",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_09a10a8cf9334c51857397ed50398c8e",
       "value": "Searching best thr : 100%"
      }
     },
     "09a10a8cf9334c51857397ed50398c8e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1f3989a0c01248328e16875075e9d1c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_08983a9c6aff42578980f4f7113c3ee2",
        "IPY_MODEL_22cfcc0a7cc6455fbf3bb7c788c8a4e1",
        "IPY_MODEL_c8392e8075224e3b8a020a16c1a08447"
       ],
       "layout": "IPY_MODEL_6cec9a2c2fac450d87248aed8dd62f86"
      }
     },
     "22cfcc0a7cc6455fbf3bb7c788c8a4e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dffe80502d954bdea0bbb6353dbf5515",
       "max": 20,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7ce1b34a4f864a42a6619eec82311eb0",
       "value": 20
      }
     },
     "4411aefc021d46d0ada7b645eb53ec48": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6cec9a2c2fac450d87248aed8dd62f86": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7ce1b34a4f864a42a6619eec82311eb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "83fe40a0b8f047cc8602206909d42361": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9384babdb7054d55aecdf3e989ddc926": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c8392e8075224e3b8a020a16c1a08447": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_83fe40a0b8f047cc8602206909d42361",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_9384babdb7054d55aecdf3e989ddc926",
       "value": " 20/20 [04:34&lt;00:00, 12.66s/it]"
      }
     },
     "dffe80502d954bdea0bbb6353dbf5515": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
